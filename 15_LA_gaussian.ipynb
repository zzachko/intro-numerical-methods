{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<table>\n",
    " <tr align=left><td><img align=left src=\"./images/CC-BY.png\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license. (c) Kyle T. Mandli</td>\n",
    "</table>\n",
    "\n",
    "Note:  This material largely follows the text \"Numerical Linear Algebra\" by Trefethen and Bau (SIAM, 1997) and is meant as a guide and supplement to the material presented there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian Elimination\n",
    "\n",
    "Gaussian elimination is the process where one transforms a matrix or linear system through a series of operations into one that is at the very least upper triangular (it is often also presented as including the operation that transforms $A$ completely to diagonal).  These series of operations can be written as a sequence of successive matrix-matrix multiplications by lower triangular matrices.  Letting these \"elimination matrices\" be $E_j$ and the resulting upper triangular matrix be $U$ we can write this as\n",
    "$$\n",
    "    \\overbrace{E_{m-1} \\cdots E_2 E_1}^{L^{-1}} A = U.\n",
    "$$\n",
    "Labeling the successive operations as $L^{-1}$ allows us to move $L$ to the other side of the equation and we see that in fact what we have done is computed another factorization of the matrix $A$ called the $LU$ factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "As an example of this process lets consider the matrix\n",
    "$$\n",
    "    A = \\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "        4 & 3 & 3 & 1 \\\\\n",
    "        8 & 7 & 9 & 5 \\\\\n",
    "        6 & 7 & 9 & 8\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The first step is to remove the values in the first column below the diagonal, to do this we can multiply by the matrix\n",
    "\n",
    "$$\n",
    "    E_1 = \\begin{bmatrix}\n",
    "         1 &   &   &  \\\\\n",
    "        -2 & 1 &   &  \\\\\n",
    "        -4 &   & 1 &  \\\\\n",
    "        -3 &   &   & 1\n",
    "    \\end{bmatrix}\\quad\\text{so that}\\quad E_1 A = E_1\\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "        4 & 3 & 3 & 1 \\\\\n",
    "        8 & 7 & 9 & 5 \\\\\n",
    "        6 & 7 & 9 & 8\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "          & 1 & 1 & 1 \\\\\n",
    "          & 3 & 5 & 5 \\\\\n",
    "          & 4 & 6 & 8\n",
    "    \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To construct $E_1$, we first define the element $a_{11} = 2$ as the \"Pivot\" and the $i,1$ component of $E_1$ as \n",
    "the _negative_ of the \"multiplier\"\n",
    "$$\n",
    "    \\ell_{i,1} = \\frac{a_{i1}}{a_{11}}\n",
    "$$\n",
    "which is the number,  that, when multiplied by the pivot and _subtracted_ from the $a_{i1}$ element puts a zero in the $i,1$ position.  Put another way  each row of $E_1$ subtracts some multiple of the first row from each row (except the first which remains the same)  that put's a zero below the diagonal and changes all the other elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once the first column is zero'd out below the diagonal,  we can repeat the process for the smaller $3\\times3$ matrix starting at the  ${22}$ element\n",
    "$$\n",
    "E_1 A = \\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "          & 1 & 1 & 1 \\\\\n",
    "          & 3 & 5 & 5 \\\\\n",
    "          & 4 & 6 & 8\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The next step is to remove the values below the diagonal of the second column.  This can be done with\n",
    "$$\n",
    "    E_2 = \\begin{bmatrix}\n",
    "         1 &    &   &   \\\\\n",
    "           &  1 &   &   \\\\\n",
    "           & -3 & 1 &   \\\\\n",
    "           & -4 &   & 1\n",
    "    \\end{bmatrix} \\text{ so that } E_2 E_1 A = \\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "          & 1 & 1 & 1 \\\\\n",
    "          &   & 2 & 2 \\\\\n",
    "          &   & 2 & 4\n",
    "    \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally we multiply $A$ by $E_3$ defined as\n",
    "$$\n",
    "    E_3 = \\begin{bmatrix}\n",
    "         1 &   &    &   \\\\\n",
    "           & 1 &    &   \\\\\n",
    "           &   &  1 &   \\\\\n",
    "           &   & -1 & 1\n",
    "    \\end{bmatrix} \\text{ so that } E_3 E_2 E_1 A = \\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "          & 1 & 1 & 1 \\\\\n",
    "          &   & 2 & 2 \\\\\n",
    "          &   &   & 2\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "completing the factorization with\n",
    "$$\n",
    "    L^{-1} = E_3 E_2 E_1 = \\begin{bmatrix}\n",
    "         1 &   &    &   \\\\\n",
    "           & 1 &    &   \\\\\n",
    "           &   &  1 &   \\\\\n",
    "           &   & -1 & 1\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "         1 &    &   &   \\\\\n",
    "           &  1 &   &   \\\\\n",
    "           & -3 & 1 &   \\\\\n",
    "           & -4 &   & 1\n",
    "    \\end{bmatrix} \n",
    "    \\begin{bmatrix}\n",
    "         1 &   &   &   \\\\\n",
    "        -2 & 1 &   &   \\\\\n",
    "        -4 &   & 1 &   \\\\\n",
    "        -3 &   &   & 1\n",
    "    \\end{bmatrix}\n",
    "$$ \n",
    "and\n",
    "$$\n",
    "    U = \\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "          & 1 & 1 & 1 \\\\\n",
    "          &   & 2 & 2 \\\\\n",
    "          &   &   & 2\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can actually easily invert $L$ (but don't really need to as you will find that $L$ is just a lower triangular matrix with 1 on the diagonal and the lower triangular elements are just the multipliers in their respective positions i.e.\n",
    "\n",
    "$$\n",
    "L_{ij}= \\ell_{ij}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "in the and finally can write $A$ as\n",
    "$$\n",
    "    A = LU =\n",
    "    \\begin{bmatrix}\n",
    "         1 &   &   &   \\\\\n",
    "         2 & 1 &   &   \\\\\n",
    "         4 & 3 & 1 &   \\\\\n",
    "         3 & 4 & 1 & 1\n",
    "    \\end{bmatrix}\\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "          & 1 & 1 & 1 \\\\\n",
    "          &   & 2 & 2 \\\\\n",
    "          &   &   & 2\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Put another way,  the matrix $L$ just shows how the rows of $A$ can be constructed from the rows of $U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solving $A\\mathbf{x} = \\mathbf{b}$\n",
    "\n",
    "Given our factorization $A=LU$ it is now straightforward to solve the linear system $A\\mathbf{x} = \\mathbf{b}$ \n",
    "in just a few steps\n",
    "\n",
    "\n",
    "1. Substitute $A=LU$  in our original equation to get\n",
    "$$\n",
    "    LU\\mathbf{x} = \\mathbf{b}\n",
    "$$\n",
    "\n",
    "1. Define $\\mathbf{c} = U\\mathbf{x}$  and solve $L \\mathbf{c} =  \\mathbf{b}$ using forward substitution.\n",
    "\n",
    "1. Solve  $U \\mathbf{x} = \\mathbf{c}$ using backward substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Forward Substitution\n",
    "\n",
    "For forward substitution we proceed from the first row and progress downwards through the matrix.  We can then consider the general $i$th row with\n",
    "$$\n",
    "    L_{i,1} y_1 + L_{i,2} y_2 + \\cdots + L_{i,i-1} y_{i-1} + y_i = b_i\n",
    "$$\n",
    "noting that we are using the fact that the matrix $L$ has 1 on its diagonal.  We can now solve for $y_i$ as\n",
    "$$\n",
    "    y_i = b_i - \\left( L_{i,1} y_1 + L_{i,2} y_2 + \\cdots + L_{i,i-1} y_{i-1} \\right ).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Backward Substitution\n",
    "\n",
    "Backwards substitution requires us to move from the last row of $U$ and move upwards.  We can consider again the general $i$th row with\n",
    "$$\n",
    "    U_{i,i} x_i + U_{i,i+1} x_{i+1} + \\ldots + U_{i,m-1} x_{m-1} + U_{i,m} x_m = y_i.\n",
    "$$\n",
    "We can now solve for $x_i$ as\n",
    "$$\n",
    "    x_i = \\frac{1}{U_{i,i}} \\left( y_i - ( U_{i,i+1} x_{i+1} + \\ldots + U_{i,m-1} x_{m-1} + U_{i,m} x_m) \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unfortunately,  in most cases this will actually be unstable and can fail on even well-conditioned matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pivoting\n",
    "\n",
    "As you may recall from your linear algebra course pivoting of the rows and columns of $A$ is often an important addition to Gaussian elimination to ensure that we can in fact factorize the matrix.  As a simple example take the matrix\n",
    "$$\n",
    "    A = \\begin{bmatrix} 0 & 1 \\\\ 1 & 1 \\end{bmatrix}.\n",
    "$$\n",
    "Without switching  the rows,  Gaussian elimination would fail at the first step! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A more insidious example is given by  the matrix\n",
    "\n",
    "$$\n",
    "    A = \\begin{bmatrix} \\epsilon & 1 \\\\ 1 & 1 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "on a finite precision machine where $\\epsilon < \\epsilon_{mach}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just consider the solution by Gaussian elimination of the two identical problems\n",
    "\n",
    "$$\n",
    "    \\begin{bmatrix} \\epsilon & 1 \\\\ 1 & 1 \\end{bmatrix}\\mathbf{x} = \\begin{bmatrix}  1 \\\\ 2 \\end{bmatrix}\\quad\\text{and}\\quad \\begin{bmatrix}1 & 1 \\\\ \\epsilon & 1  \\end{bmatrix}\\mathbf{x} = \\begin{bmatrix}  2 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "on a finite precision machine where $\\epsilon < \\epsilon_{mach}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " In principle any row and column can be **pivoted** so that at each step we have the maximum value being used (on the diagonal) to perform the operations that compose the matrices $E_j$.  In practice however we restrict ourselves to only pivoting rows of the matrix (called partial pivoting).\n",
    " \n",
    "The basic algorithm just adds an extra step of finding the largest element in any column $k$ in rows $m\\geq k$, and swapping row $m$ for row $k$.  Row swaps can also be accomplished by multiplying by a permutation matrix $P_k$ which just reorders the rows of the identity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider again the example from above and switch the 1st and 3rd rows using the criteria that we always want to use the largest value to do perform the reduction.  Defining the first permutation matrix as\n",
    "$$\n",
    "    P_1 = \\begin{bmatrix}\n",
    "          &   & 1 &   \\\\\n",
    "          & 1 &   &   \\\\\n",
    "        1 &   &   &   \\\\\n",
    "          &   &   & 1\n",
    "    \\end{bmatrix} \\quad \\text{so that} \\quad\n",
    "    P_1 A = P_1\\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "        4 & 3 & 3 & 1 \\\\\n",
    "        8 & 7 & 9 & 5 \\\\\n",
    "        6 & 7 & 9 & 8\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\n",
    "        8 & 7 & 9 & 5 \\\\\n",
    "        4 & 3 & 3 & 1 \\\\\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "        6 & 7 & 9 & 8\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now defining the first $E_1$ as\n",
    "$$\n",
    "    E_1 = \\begin{bmatrix}\n",
    "        1 &   &   &   \\\\\n",
    "        -\\frac{1}{2} & 1 &   &   \\\\\n",
    "        -\\frac{1}{4} &   & 1 &   \\\\\n",
    "        -\\frac{3}{4} &   &   & 1\n",
    "    \\end{bmatrix} \\quad \\text{so that} \\quad\n",
    "    E_1 P_1 A = \\begin{bmatrix}\n",
    "        8 & 7 & 9 & 5 \\\\\n",
    "          & -\\frac{1}{2} & -\\frac{3}{2} & -\\frac{3}{2} \\\\\n",
    "          & -\\frac{3}{4} & -\\frac{5}{4} & -\\frac{5}{4} \\\\\n",
    "          & \\frac{7}{4} & \\frac{9}{4} & \\frac{17}{4}\n",
    "    \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again examining the remaining values in column 2 the maximum value lies in row 4 so we want to interchange this with the second row (note that we do not want to move the first row as that will bring non-zero values into the first column below the diagonal).\n",
    "$$\n",
    "    P_2 = \\begin{bmatrix}\n",
    "        1 &   &   &   \\\\\n",
    "          &   &   & 1 \\\\\n",
    "          &   & 1 &   \\\\\n",
    "          & 1 &   &\n",
    "    \\end{bmatrix}  \\quad \\text{and} \\quad \n",
    "    E_2 = \\begin{bmatrix}\n",
    "        1 &   &   &   \\\\\n",
    "          & 1 &   &   \\\\\n",
    "          & \\frac{3}{7} & 1 &   \\\\\n",
    "          & \\frac{2}{7}  &   & 1\n",
    "    \\end{bmatrix}  \\quad  \\text{so that}  \\quad \n",
    "    E_2 P_2 E_1 P_1 A = \\begin{bmatrix}\n",
    "        8 &            7 &            9 &             5 \\\\\n",
    "          &  \\frac{7}{4} &  \\frac{9}{4} &  \\frac{17}{4} \\\\\n",
    "          &              & -\\frac{2}{7} &   \\frac{4}{7} \\\\\n",
    "          &              & -\\frac{6}{7} &  -\\frac{2}{7}\n",
    "    \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally\n",
    "$$\n",
    "    P_3 = \\begin{bmatrix}\n",
    "        1 &   &   &   \\\\\n",
    "          & 1 &   &   \\\\\n",
    "          &   &   & 1 \\\\\n",
    "          &   & 1 &\n",
    "    \\end{bmatrix}  \\quad \\text{and} \\quad \n",
    "    E_3 = \\begin{bmatrix}\n",
    "        1 &   &   &   \\\\\n",
    "          & 1 &   &   \\\\\n",
    "          &   & 1 &   \\\\\n",
    "          &   & -\\frac{1}{3} & 1\n",
    "    \\end{bmatrix} \\quad \\text{so that} \\quad\n",
    "    E_3 P_3 E_2 P_2 E_1 P_1 A = \\begin{bmatrix}\n",
    "        8 &            7 &            9 &             5 \\\\\n",
    "          &  \\frac{7}{4} &  \\frac{9}{4} &  \\frac{17}{4} \\\\\n",
    "          &              & -\\frac{6}{7} &  -\\frac{2}{7} \\\\\n",
    "          &              &              &   \\frac{2}{3} \\\\\n",
    "    \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LU Factorization with Partial Pivoting\n",
    "\n",
    "Due to the nature of the pivot matrices we can disentangle them from the matrices $E_j$.  Right now we have\n",
    "$$\n",
    "    E_3 P_3 E_2 P_2 E_1 P_1 A = U\n",
    "$$\n",
    "where what we want is\n",
    "$$\n",
    "    (E'_3 E'_2 E'_1) P_3 P_2 P_1 A = U.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It turns out we can easily do this by\n",
    "$$\n",
    "    E'_3 = E_3, \\quad E'_2 = P_3 E_2 P_3^{-1}, \\quad \\text{and} \\quad E'_1 = P_3 P_2 E_1 P_2^{-1} P_3^{-1}.\n",
    "$$\n",
    "(Moreover, because Permutation matrices are unitary matrices,  then $P_k^{-1}=P_k^T$ so no inverses need be computed)\n",
    "These new matrices $E'_j$ can easily be computed and it turns out that the $E'_j$ matrices have the same structure with the rows permuted accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In general then the $LU$ factorization with partial pivoting of the above example can be written as\n",
    "$$\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "          &   & 1 &   \\\\\n",
    "          &   &   & 1 \\\\\n",
    "          & 1 &   &   \\\\\n",
    "        1 &   &   & \n",
    "    \\end{bmatrix}}_{P = P_3 P_2 P_1} \\underbrace{\\begin{bmatrix}\n",
    "        2 & 1 & 1 & 0 \\\\\n",
    "        4 & 3 & 3 & 1 \\\\\n",
    "        8 & 7 & 9 & 5 \\\\\n",
    "        6 & 7 & 9 & 8\n",
    "    \\end{bmatrix}}_{A} = \n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        1           &              &              &   \\\\\n",
    "        \\frac{3}{4} &            1 &              &   \\\\\n",
    "        \\frac{1}{2} & -\\frac{2}{7} &            1 &   \\\\\n",
    "        \\frac{1}{4} & -\\frac{3}{7} & \\frac{1}{3}  & 1 \\\\\n",
    "    \\end{bmatrix}}_{L}\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        8 &            7 &            9 &             5 \\\\\n",
    "          &  \\frac{7}{4} &  \\frac{9}{4} &  \\frac{17}{4} \\\\\n",
    "          &              & -\\frac{6}{7} &  -\\frac{2}{7} \\\\\n",
    "          &              &              &   \\frac{2}{3} \\\\\n",
    "    \\end{bmatrix}}_{U}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some code for the LU with partial pivoting (translated from the matlab, courtesy of Cleve Moler)\n",
    "\n",
    "Here is an implementation of an \"in-place\" algorithm transforming a matrix in place from $A$ to a matrix $LU$ where the diagonal and upper elements are replaced with $U$ and the strictly lower diagonal part of A is replaced with the multipliers in $L$.  This routine also returns a permuted index vector $p$ such that $b[p]= P\\mathbf{b}$\n",
    "\n",
    "A little hand-drawn animation of this algorithm, may go a long way to understanding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def lutx(A):\n",
    "    \"\"\"LUTX Triangular factorization, textbook version\n",
    "    \n",
    "    translated to python from the original Matlab from Cleve Moler\n",
    "    \n",
    "    L,U,p = lutx(A) produces a unit lower triangular matrix L,\n",
    "    an upper triangular matrix U, and a permutation vector p,\n",
    "    so that L*U = A(p,:)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    A: ndarray\n",
    "        square numpy array\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    L: ndarray NxN\n",
    "        Lower triangular matrix with 1's on the diagonal and multipliers in place\n",
    "    U: ndarray NxN\n",
    "        Upper triangular matrix with Pivots on the diagonal\n",
    "    p: ndarray size(N)\n",
    "        permutation array\n",
    "    \"\"\"\n",
    "\n",
    "    n,m = A.shape\n",
    "    assert( n == m)\n",
    "    \n",
    "    # make a deep copy of the original matrix into U\n",
    "    U = A.copy()\n",
    "    p = numpy.array(range(n))\n",
    "\n",
    "    for k in range(n-1):\n",
    "        # Find index of largest element below diagonal in k-th column\n",
    "        m = numpy.argmax(numpy.abs(U[k:,k])) + k\n",
    "        # Skip elimination if column is zero\n",
    "        if U[m,k] != 0. :\n",
    "            # Swap pivot row\n",
    "            if m != k : \n",
    "                U[[k, m],:] = U[[m, k],:]\n",
    "                p[[k, m]] = p[[m, k]];\n",
    "        # Compute multipliers in place\n",
    "        U[k+1:n,k] /= U[k,k]\n",
    "        #Update the remainder of the matrix \n",
    "        U[k+1:n,k+1:n] -=  numpy.outer(U[k+1:n,k],U[k,k+1:n])\n",
    "\n",
    "    # Separate result and return\n",
    "    L = numpy.tril(U,-1) + numpy.eye(n)\n",
    "    U = numpy.triu(U)\n",
    "    return L, U, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's apply this to our example problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "A = numpy.array([[2., 1., 1., 0.],\n",
    "                 [4., 3., 3., 1.],\n",
    "                 [8., 7., 9., 5.],\n",
    "                 [6., 7., 9., 8.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L, U, p = lutx(A)\n",
    "print('L=\\n{}'.format(L))\n",
    "print('U=\\n{}'.format(U))\n",
    "print('p={}'.format(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as la\n",
    "P, LL, UU = la.lu(A)\n",
    "print('L=\\n{}'.format(LL))\n",
    "print('U=\\n{}'.format(UU))\n",
    "print('P={}'.format(P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('A=\\n{}\\n'.format(A))\n",
    "print('p = {}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('PA=\\n{}'.format(A[p,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('LU=\\n{}'.format(L.dot(U)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## And let's use this to solve  $A\\mathbf{x} = \\mathbf{b}$\n",
    "\n",
    "Given our factorization $PA=LU$ it is now straightforward to solve the linear system $A\\mathbf{x} = \\mathbf{b}$ \n",
    "in just a few steps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Multiply both sides by $P$ to yield $PA\\mathbf{x} = P\\mathbf{b}$ and substitute $PA=LU$ to get\n",
    "\n",
    "$$\n",
    "    LU\\mathbf{x} = P\\mathbf{b}\n",
    "$$\n",
    "\n",
    "1. Define $\\mathbf{c} = U\\mathbf{x}$  and solve $L \\mathbf{c} = P  \\mathbf{b}$ using forward substitution.\n",
    "\n",
    "1. Solve  $U \\mathbf{x} = \\mathbf{c}$ using backward substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here we'll just use `numpy.linalg.solve` to solve the individual triangular systems but we could use more efficient forward and backward substitution codes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = numpy.random.rand(4)\n",
    "b = A.dot(x)\n",
    "\n",
    "L,U,p = lutx(A)\n",
    "\n",
    "c = numpy.linalg.solve(L,b[p])\n",
    "xp = numpy.linalg.solve(U,c)\n",
    "\n",
    "print(x)\n",
    "print(xp)\n",
    "\n",
    "numpy.testing.assert_allclose(x,xp)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = numpy.linalg.solve(A,b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### computational Costs\n",
    "\n",
    "Gaussian elimination with partial pivoting is an extremely robust algorithm even for ill-conditioned matrices, however it is not cheap.  With a little work, it is easy to show that for a dense $n\\times n$ matrix,  the $LU$ decomposition takes $O(n^3/3)$ operations, while the two forward and back substitutions take in total $O(n^2)$ operations.\n",
    "\n",
    "For the large (but sparse) matrices that often arise from numerical PDE's, there are a host of other iterative methods that, under certain circumstances can solve linear systems in many fewer flops.  But that is another story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LU vs the matrix inverse $A^{-1}$\n",
    "\n",
    "Formally,  one can solve $A\\mathbf{x}=\\mathbf{b}$ using the $PA=LU$ or as \n",
    "\n",
    "$$\n",
    "    \\mathbf{x} = A^{-1}\\mathbf{b}\n",
    "$$\n",
    "\n",
    "which will formally have $O(N^3 + N^2)$ operations (which is about 3 times slower than the LU).  However, in general, one rarely needs to calculate $A^{-1}$ and for many matrices arising from 2-pt BVP's it is a particulary bad idea as even if $A$ is sparse (e.g. tridiagonal),  the inverse $A^{-1}$ can often be dense.  The LU decomposition however, will preserve the sparsity structure for banded matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will demonstrate this here using the simplest 2-pt boundary value problem (the 1-D Poisson problem)\n",
    "\n",
    "$$\n",
    "    u_{xx} = f(x)\\quad u(0)=u(L)=0\n",
    "$$\n",
    "\n",
    "or in its discrete form\n",
    "\n",
    "$$\n",
    "    D\\mathbf{u} = \\mathbf{f}\n",
    "$$\n",
    "\n",
    "where $D$ is a tridiagonal finite difference matrix, $\\mathbf{u}=u(\\mathbf{x})$ is the discrete solution and $\\mathbf{f} = f(\\mathbf{x})$ is the discrete approximation to the RHS.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reusing our sparse matrix code from the ODE BVP notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from fdcoeffV import fdcoeffV\n",
    "from scipy.sparse import lil_matrix, identity, spdiags\n",
    "from scipy.sparse.linalg import spsolve, splu, inv\n",
    "\n",
    "def D2(x,bcs=['dirichlet', 'dirichlet']):\n",
    "    \"\"\"  \n",
    "        Assemble a general sparse second-order finite-difference approximation to d/dx^2 on a possibly irregular mesh\n",
    "        First and last rows are set by string bcs\n",
    "        \n",
    "        parameters:\n",
    "        -----------\n",
    "        x: numpy.array\n",
    "            mesh coordinates\n",
    "        bcs: list of strings for boundary conditions e.g [left_string, right_string] where\n",
    "            the strings can be either 'dirichlet' or 'neumann'\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    A = lil_matrix((N,N))\n",
    "    if bcs[0] == 'dirichlet':\n",
    "        A[0,0] = 1.\n",
    "    elif bcs[0] == 'neumann':\n",
    "        A[0,0:3] = fdcoeffV(1,x[0],x[:3])\n",
    "    else:\n",
    "        raise ValueError('no known BC type for left boundary {}'.format(bcs[0]))\n",
    "        \n",
    "    if bcs[1] == 'dirichlet':\n",
    "        A[-1,-1] = 1.\n",
    "    elif bcs[1] == 'neumann':\n",
    "        A[-1,-3:] = fdcoeffV(1,x[-1],x[-3:])\n",
    "    else:\n",
    "        raise ValueError('no known BC type for right boundary {}'.format(bcs[1]))\n",
    "        \n",
    "    for i in range(1,N-1):\n",
    "        A[i, i-1:i+2] = fdcoeffV(2, x[i], x[i-1:i+2] )        \n",
    "    return A.tocsc()\n",
    "\n",
    "def RHS(x, f, bvalues):\n",
    "    \"\"\" Set the rhs vector\n",
    "    \n",
    "        parameters\n",
    "        ----------\n",
    "        x: numpy.array\n",
    "            mesh coordinates\n",
    "        f: callable\n",
    "            rhs function for interior points called on f(x[1:-2])\n",
    "        bvalues:  numpy.array (len 2)\n",
    "            values for boundary conditions (either dirichlet or neumann)        \n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(x)\n",
    "    rhs = numpy.empty(N)\n",
    "    rhs[[0, N-1]] = bvalues\n",
    "    rhs[1:-1] = f(x[1:-1])\n",
    "    \n",
    "    return rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll set up a small $N$-point Finite Difference problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "N=101\n",
    "x = numpy.linspace(0,1.,N)\n",
    "A = D2(x)\n",
    "func = lambda x: x\n",
    "f = RHS(x,func,[0.,0.])\n",
    "\n",
    "u = spsolve(A,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "axes = fig.add_subplot(1,2,1)\n",
    "axes.spy(A)\n",
    "axes.set_title('Sparsity of $A$')\n",
    "\n",
    "axes = fig.add_subplot(1,2,2)\n",
    "axes.plot(x,u,'bo-')\n",
    "axes.grid()\n",
    "axes.set_xlabel('$x$')\n",
    "axes.set_ylabel('$u$')\n",
    "axes.set_title('Solution $u$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Visualizing $L,U$ and $A^{-1}$\n",
    "\n",
    "scipy.sparse  also includes routines for calculating the inverse and permuted $L,U$ decompositions of sparse matrices $A$ using the parallel sparse package ``SuperLU``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "B = splu(A, permc_spec='NATURAL')\n",
    "Ainv = inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "axes = fig.add_subplot(1,3,1)\n",
    "axes.spy(Ainv)\n",
    "axes.set_title('Sparsity of $A^{{-1}}$, nnz={}'.format(Ainv.nnz))\n",
    "\n",
    "axes = fig.add_subplot(1,3,2)\n",
    "axes.spy(B.L)\n",
    "axes.set_title('Sparsity of $B.L$, nnz={}'.format(B.L.nnz))\n",
    "\n",
    "axes = fig.add_subplot(1,3,3)\n",
    "axes.spy(B.U)\n",
    "axes.set_title('Sparsity of $B.U$, nnz={}'.format(B.U.nnz))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Check\n",
    "\n",
    "And don't forget to check that we get the same answer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = (Ainv.dot(f) - B.solve(f))/numpy.finfo('float').eps\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Timing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%timeit inv(A)\n",
    "%timeit Ainv.dot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit B = splu(A)\n",
    "%timeit B.solve(f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
